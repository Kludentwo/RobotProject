\section{Localisation}
Localisation is the act of a robot finding out where it is. GPS systems are often used to do this in cases where precision is not critical, e.g. GPS navigation. If precision is critical, e.g. for a robot to drive past obstacles without hitting them, GPS is too imprecise. Other techniques must then be used. To do this, robots often have sensors, such as sonars, LIDARs or cameras. 
The localisation algorithms consists of two main parts, movement and measurement. Movement is imprecise, often because of the mechanical system. Measurements contributes with new knowledge and is therefore the part that narrows the decision, of where the robot is, in. The measurements is often also noisy, but usually less noisy than the movements.
Another important thing in localisation is probability. What is the probability of being in a certain position, given the measurement? To calculate this, Bayes rule is used.
\begin{equation}
p(x|z) = \frac{p(z|x)\cdot p(x)}{p(z)}
\end{equation}
Where $\frac{1}{p(z)}$ is the normalizing factor $\eta$.
\begin{equation}
\eta = \frac{1}{p(z)} = \frac{1}{\sum(p(z|x)\cdot p(x))}
\end{equation}
This gives us the expression:
\begin{equation}
p(x|z) = \eta \cdot p(z|x)\cdot p(x)
\end{equation}
\textbf{Example:}\\
A robot is in one of the grids in the map. It can detect if it is in a red or green grid. 
\begin{figure}[H]
\centering
\includegraphics[scale=1]{billeder/Localisation01.png}
\caption{The map in which the robot lives}
\label{fig:Localisation01}
\end{figure}
If the robot is in a green grid, it detects correctly with 75\% chance. If it is in a red grid, it detects correctly with 90\% chance.
If the robot detects green, what is the probability that it is in a green or a red grid?\\
$z = green$\\
$\eta = \frac{1}{sum(p(z|x)\cdot p(x))} = \frac{1}{0.75 \cdot \frac{3}{5} + 0.1 \cdot 2/5} = 2.04$\\\\
$x = green$\\
$p(x) = \frac{3}{5}$\\
$p(x \mid z) = \eta \cdot p(z|x)\cdot p(x) = 2.04 \cdot 0.75 \cdot \frac{3}{5} = 0.918 = 91.8\%$\\\\
$x = red$\\
$p(x) = \frac{2}{5}$\\
$p(x \mid z) = \eta \cdot p(z|x)\cdot p(x) = 2.04 \cdot 0.1 \cdot \frac{2}{5} = 0.082 = 8.2\%$
\subsection{Markov Localisation}
\input{sections/Localisation_1_MarkovLocalisation}
\subsection{Kalman Filter}
\input{sections/Localisation_2_KalmanFilter}
\subsection{Particle Filter}
The particle filter is a different kind of filter, since it uses a discrete method for finding the robots location, in contrast to the continuously methods previously discuses. \\
The method is multi-model, which means that more than one location candidate can be found. This is a very popular technique for localisation, since it is simple to understand and implement. 

Like the other filters, the particle filter does also require the map to be known, and we must be able to predict how all measurements will look in any given location. 

The particle filter can also be seen as having a prediction step and a measurement step. Before we start the measurement-prediction loop, we first select a number $M$ of particles $X$ to use in the filter. Then we place all the $M$ particles at random locations. 

\subsubsection{Prediction Step}
After the robot have moved with a motion $u_t$, we move all the particles with the same motion. On this motion we add some random noise $w_t$. If one of the particles was exactly at the robot location before we moved it, and the noise we put on the particle was the exact same as on the real robot, the new particle location would still be the same as the robot.  

\subsubsection{Measurement Step}
First we take the measurement from the real robot $z_t$. Then we compare it to all of the $M$ particles and calculate if the probability of the location of the real robot is the same as for the particle. This is done by comparing the measurement $z_t$, with the measurement that would have been at the particle location.
In this process it is important to assume that there are noise on the measurements. If we assume that the sensor is too precise we risk giving particles that are close to the real location a low probability, which is not desirable.

When we have all the probabilities for the particles $Prob_t$, we are doing resampling. The aim of resampling is to get a new set of $M$ new particles. The locations of the new particles must be randomly drawn from the old particle set with a distribution that matches the $Prob_t$ distribution. This means that a lot of the new particles are at the locations with high probability, where only a few or none is at locations with low probability.

After the resampling we continue with the prediction step, and so one. 

\subsubsection{The Algorithm}
Over time particles with at bad locations will die, and more will search the area around feasible locations. The predict - measurement steps can also be expressed as pseudo code as seen below: 
\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{billeder/ParticleFilter.png}
\caption{Particle Filter Algorithm}
\label{fig:ParticleFilter}
\end{figure}
This process runs continuously, and will over time converge to zero or one single location.

\subsubsection{Particle Filters Considerations}
A series of scenarios must be considered when using particle filters. One is the scenario where there is not placed a particle close to the real robot or all the particles around it dies. This will make the particle filter coverage around a wrong location or no location. There are several techniques tackling this problem. One easy simple solution is to look at probability and see if there is at least one good candidate. If this is not the case the filter should be reset. 

One other problem happens if the world is symmetric, this means that every measurement have multiple feasible locations, and when moved previously feasible locations still appearers equally likely. If this is the case it is impossible to know the true location. This can also in extreme cases be a problem if the world is only partially symmetric, since all the true particles can die, and only the wrong survive. When we now enter a asymmetric area all the wrong will die, and we have no particles left. This can be fixed by either resetting the filter, or by a technique where you always randomly spread out the worst $5\%$ of you particles. 

Also a balance must be found with the number of particles and the map size. The more particles the better the filter, but it will also drastically increase the calculation time. 

%------------------------------------------------